# ğŸŒ  Lyra: Asistente de AnÃ¡lisis CientÃ­fico AstronÃ³mico

**Lyra** es un asistente de inteligencia artificial diseÃ±ado para analizar, resumir y contextualizar informaciÃ³n cientÃ­fica sobre el espacio â€” en especial sobre **agujeros negros, galaxias y fenÃ³menos astrofÃ­sicos**.  
El sistema integra OCR, embeddings, bÃºsqueda semÃ¡ntica y una arquitectura **multiagente en LangChain**, simulando el flujo de trabajo de un investigador digital.

---

## ğŸ§© Objetivo del proyecto

Este proyecto forma parte del mÃ³dulo final de **IntroducciÃ³n a la Inteligencia Artificial**, y su propÃ³sito es demostrar la comprensiÃ³n prÃ¡ctica de los siguientes conceptos:

- ExtracciÃ³n y procesamiento de datos (OCR, texto, PDFs, imÃ¡genes)
- SegmentaciÃ³n (*chunking*) y embeddings usando OpenAI text-embedding-3-small
- Similitud semÃ¡ntica y bases vectoriales (Pinecone)
- Arquitectura de agentes mÃºltiples en LangChain
- InteracciÃ³n con modelos LLM de OpenAI

---

## ğŸš€ DescripciÃ³n general

**Lyra** actÃºa como un **investigador astronÃ³mico digital**.  
El usuario puede subir artÃ­culos, papers o imÃ¡genes escaneadas, y Lyra:

1. Extrae el texto (OCR si es necesario)  
2. Limpia y estructura el contenido  
3. Genera *embeddings* para anÃ¡lisis semÃ¡ntico  
4. Busca fragmentos relevantes en la base vectorial  
5. Resume, traduce o amplÃ­a el contenido  
6. Calcula variables fÃ­sicas si es necesario  
7. Genera una respuesta final coherente y validada  

Todo esto es orquestado por un **Supervisor Agent**, que decide quÃ© herramientas (agentes) activar segÃºn la solicitud del usuario.

---

## ğŸ§  Arquitectura Multiagente

Lyra utiliza una arquitectura modular basada en **LangGraph - LangChain Agents + Tools**, donde cada agente cumple un rol definido dentro del pipeline de procesamiento y anÃ¡lisis.

### ğŸ”¹ Agentes principales

| Agente | FunciÃ³n | DescripciÃ³n |
|---------|----------|-------------|
| ğŸ§¾ **Extractor** | OCR / lectura | Extrae texto desde PDFs o imÃ¡genes |
| ğŸ§¹ **Cleaner** | Limpieza de texto | Elimina ruido, caracteres errÃ³neos y sÃ­mbolos |
| ğŸ” **Analyzer** | BÃºsqueda semÃ¡ntica | Analiza embeddings y encuentra fragmentos relevantes |
| ğŸ“Š **Summarizer** | Resumen | Sintetiza informaciÃ³n en lenguaje natural |
| ğŸ’¬ **Responder** | Respuesta final | Redacta la respuesta final de Lyra |
| ğŸ§  **Contextualizer** | Contexto adicional | Agrega informaciÃ³n de fondo sobre los hallazgos |
| ğŸ” **Validator** | ValidaciÃ³n | Verifica la coherencia y exactitud cientÃ­fica |

### ğŸ”¹ Agentes complementarios

| Agente | FunciÃ³n | DescripciÃ³n |
|---------|----------|-------------|
| ğŸ§® **Computation** | CÃ¡lculos fÃ­sicos | Calcula masas, radios, distancias, etc. |
| ğŸ“š **Researcher** | InvestigaciÃ³n externa | Consulta APIs (NASA, arXiv, Wikipedia) |
| ğŸ§© **Planner** | PlanificaciÃ³n | Decide la secuencia Ã³ptima de acciones |
| ğŸ’¾ **Memory** | Memoria | Almacena contexto de interacciÃ³n |
| ğŸ§° **KnowledgeGraph** | Relaciones conceptuales | Crea conexiones entre conceptos cientÃ­ficos |

---

### ğŸ“š Ejemplo de uso

Entrada:

"Subo una imagen del artÃ­culo del EHT sobre la primera fotografÃ­a de un agujero negro."

Salida (Lyra):

"El artÃ­culo describe los resultados del Event Horizon Telescope (EHT) en 2019, donde se obtuvo la primera imagen del agujero negro M87*.
Se estima su masa en 6.5 mil millones de masas solares.
Esta observaciÃ³n confirma las predicciones de la relatividad general en entornos extremos."

---

## âš™ï¸ ConfiguraciÃ³n e InstalaciÃ³n

### Requisitos

- Python 3.8+
- Cuenta de OpenAI (para embeddings y LLM)
- Cuenta de Pinecone (para vector store)

### InstalaciÃ³n

1. Clona el repositorio y navega al directorio `Backend`:
```bash
cd Backend
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

### Variables de Entorno

Crea un archivo `.env` en el directorio `Backend` con las siguientes variables:

```env
# OpenAI (requerido)
OPENAI_API_KEY=tu_clave_openai_aqui

# Pinecone (requerido)
PINECONE_API_KEY=tu_clave_pinecone_aqui
PINECONE_REGION=us-east-1  # RegiÃ³n AWS para el Ã­ndice serverless (opcional, por defecto: us-east-1)
PINECONE_INDEX_NAME=lyra-vectorstore  # Nombre del Ã­ndice (opcional, por defecto: lyra-vectorstore)

# AWS (opcional, solo si usas Textract para OCR de imÃ¡genes y PDFs escaneados)
# Sin esto, solo funcionarÃ¡ la extracciÃ³n de texto de PDFs legibles (PyPDF2)
AWS_ACCESS_KEY_ID=tu_clave_aws_aqui
AWS_SECRET_ACCESS_KEY=tu_secret_aws_aqui
AWS_REGION=us-east-1
```

### ConfiguraciÃ³n de Pinecone

1. Crea una cuenta en [Pinecone](https://www.pinecone.io/)
2. ObtÃ©n tu API key desde el dashboard de Pinecone
3. El Ã­ndice se crearÃ¡ automÃ¡ticamente la primera vez que ejecutes la aplicaciÃ³n
4. El Ã­ndice usa embeddings de **text-embedding-3-small** de OpenAI (1536 dimensiones)

### Ejecutar la API

```bash
python src/main.py --port 8000
```

La API estarÃ¡ disponible en `http://localhost:8000`

### Ejecutar con Uvicorn (Recomendado)

```bash
uvicorn src.main:app --reload --port 8000
```

### Verificar InstalaciÃ³n

```bash
# Verificar que el servidor responde
curl http://localhost:8000/health
```

---

## ğŸ”Œ API Endpoints

### Consultas

- **POST** `/api/query` - Procesar consulta de texto
  ```json
  {
    "query": "Â¿QuÃ© es un agujero negro?",
    "session_id": "opcional"
  }
  ```

- **POST** `/api/upload` - Subir y procesar documentos
  ```bash
  curl -X POST "http://localhost:8000/api/upload" \
    -F "file=@documento.pdf" \
    -F "query=Analiza este documento"
  ```

### Realtime API

- **POST** `/api/realtime/connect` - Conectar a OpenAI Realtime API
- **WebSocket** `/api/realtime/ws` - ConexiÃ³n WebSocket para streaming

### Utilidades

- **GET** `/health` - Estado del servidor
- **GET** `/docs` - DocumentaciÃ³n interactiva (Swagger UI)

---

## ğŸ§  Arquitectura LangGraph

El sistema utiliza **LangGraph** para orquestar el flujo de trabajo multiagente:

### Componentes Principales

- **SupervisorGraph**: Grafo principal que coordina los agentes
- **AgentState**: Estado tipado que se mantiene a travÃ©s del flujo
- **ToolFactory**: Factory para crear y gestionar herramientas
- **ContextManager**: GestiÃ³n de contexto compartido
- **ResourceManager**: GestiÃ³n de recursos (VectorStore, LLMs)

**DocumentaciÃ³n tÃ©cnica**: Ver [docs/README.md](docs/README.md)

---

## ğŸ“š DocumentaciÃ³n Adicional

**Toda la documentaciÃ³n tÃ©cnica estÃ¡ centralizada en el directorio `docs/` de la raÃ­z del proyecto:**

- **[docs/README.md](../docs/README.md)** - Ãndice completo de documentaciÃ³n
- **[docs/backend/langgraph.md](../docs/backend/langgraph.md)** - ImplementaciÃ³n LangGraph
- **[docs/backend/agents.md](../docs/backend/agents.md)** - DocumentaciÃ³n detallada de agentes
- **[docs/backend/connection.md](../docs/backend/connection.md)** - ConexiÃ³n Frontend-Backend
- **[docs/backend/tools.md](../docs/backend/tools.md)** - VerificaciÃ³n de herramientas
- **[docs/backend/web-search.md](../docs/backend/web-search.md)** - BÃºsqueda web con DuckDuckGo

---

## ğŸ”§ Desarrollo

### Estructura de CÃ³digo

```
src/
â”œâ”€â”€ agents/              # Agentes especializados
â”‚   â”œâ”€â”€ graph/          # ImplementaciÃ³n LangGraph
â”‚   â”‚   â”œâ”€â”€ supervisor_graph.py
â”‚   â”‚   â”œâ”€â”€ state.py
â”‚   â”‚   â””â”€â”€ tool_factory.py
â”‚   â””â”€â”€ *.py            # Agentes individuales
â”œâ”€â”€ core/               # Funcionalidades principales
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â””â”€â”€ chunking.py
â”œâ”€â”€ interface/          # API y endpoints
â”‚   â”œâ”€â”€ api.py
â”‚   â””â”€â”€ realtime_api.py
â””â”€â”€ main.py            # Punto de entrada
```

### Agregar un Nuevo Agente

1. Crea el archivo del agente en `src/agents/`
2. Implementa las funciones de herramienta
3. Registra el agente en `supervisor_graph.py`
4. Agrega la herramienta en `tool_factory.py`

---

## ğŸ› Troubleshooting

### Error: "Pinecone index not found"
- Verifica que `PINECONE_API_KEY` estÃ© configurada
- El Ã­ndice se crea automÃ¡ticamente en el primer uso

### Error: "OpenAI API key not found"
- Verifica que `OPENAI_API_KEY` estÃ© en el archivo `.env`

### Error: "Module not found"
- AsegÃºrate de estar en el entorno virtual: `source venv/bin/activate`
- Reinstala dependencias: `pip install -r requirements.txt`

---

## ğŸ“ Notas

- El sistema usa **Singleton** para recursos compartidos
- Los embeddings usan `text-embedding-3-small` (1536 dimensiones)
- El vector store se inicializa de forma lazy (solo cuando se necesita)
- Compatible con Python 3.8+